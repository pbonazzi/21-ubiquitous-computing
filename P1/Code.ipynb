{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ex1_data.dict.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be42ab663622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# .item() is needed as np.load() returns a structured array that needs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# to be converted back to a dict. File should be in same location as code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ex1_data.dict.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ex1_data.dict.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# Load data\n",
    "# .item() is needed as np.load() returns a structured array that needs\n",
    "# to be converted back to a dict. File should be in same location as code.\n",
    "data = np.load(\"ex1_data.dict.npy\", allow_pickle=True).item() \n",
    "\n",
    "print(data.keys())\n",
    "print(\"Length of chest data: {}\".format(len(data[\"chest\"])))\n",
    "print(\"12387th sample of wrist: {}\".format(data[\"wrist\"][12387]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.1\n",
    "What percentage of the total recorded time did the subject spend at Jungfraujoch (time betweenarrival and departure)?  You may use the length of the shortest data trace as base value for 100%.(max.  1pt, Full pts tol±0.2%, 10% Pts tol±3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of chest trace: 454038\n",
      "length of head trace: 447464\n",
      "length of wrist trace: 446831\n",
      "length of ankle trace: 451008\n"
     ]
    }
   ],
   "source": [
    "for key in data:\n",
    "        print(\"length of {} trace: {}\".format(key, len(data[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c09db4d2d274bd4a1e47547a83be554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "fig,ax=plt.subplots(nrows=2,ncols=1,figsize=(10, 6), sharex=True)\n",
    "\n",
    "for key in data:\n",
    "        ax[0].plot(data[key], label=key)\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[1].plot(data['wrist'], label=key)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortes trace: wrist, 446801 samples. Stay at Jungfraujoch: [95050, 300540] => 46.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.2\n",
    "As it is not physically possible to turn on or off all devices at the same time, there is a misalign-ment between the data traces.  Shorten the traces to match the device that was turned on lastso that samples of all devices are synchronous by array index.  Do this as precisely as possible.How many samples did you remove from the beginning each trace?2(max.  2pt, Full pts tol±8samples, 10% Pts tol±50 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b0dce7aac14ea9b36972c011c6c70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "fig,ax=plt.subplots(nrows=2,ncols=1,figsize=(10, 6), sharex=True)\n",
    "\n",
    "for key in data:\n",
    "        ax[1].plot(data[key], label=key)\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"ex1_data.dict.npy\", allow_pickle=True).item() \n",
    "\n",
    "data['chest'] = data['chest'][:]\n",
    "data['wrist'] = data['wrist'][56:]\n",
    "data['ankle'] = data['ankle'][174:]\n",
    "data['head']  = data['head'][119:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3881b00411ad45cd809f3b68eae8e847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "fig,ax=plt.subplots(nrows=2,ncols=1,figsize=(10, 6), sharex=True)\n",
    "\n",
    "for key in data:\n",
    "    if key == 'head':\n",
    "        ax[1].plot(data[key]-1000, label=key)\n",
    "    else:\n",
    "        ax[1].plot(data[key], label=key)\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.3\n",
    "What  was  the  sampling  rate  of  the  sensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "The sampling rate is 13.7.  Tolerance for full points: ±0.6 Hz points awarded fortolerances of up to ±4.5 Hz.\n",
    "The sampling rate can be found using various tactics.  Using the constraints of the environment, we have to find out how much time the subject needed to travel from one altitude toanother.  One example is using the train schedule from the Eigergletscher station to Jungfraujoch (which is the only means to reach Jungfraujoch).  Under the assumption that the train picks up vertical speed 1 minute after scheduled departure (door locking etc.)  and the same at arrival, you get a sampling frequency of 12.9 for the journey up and 13.8 for the journey down.  Another way ist to identify the car ride from Grindelwald to Brunig Pass and lookup the driving time on Google Maps (yields a sampling rate of 13.8).  And there are more options similar to those (elevator ride duration and so on). To achieve a good result, averaging over several calculations may help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = dict()\n",
    "for key in data:\n",
    "    elevation[key] = [44307.69*(1-(p/10194000)**(0.190284)) for p in data[key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.1\n",
    "On what date did the subject conduct the trip to Jungfraujoch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  measured  air  pressure  at  the  Sphinx  observatory  was  between  655.3  and  656.2  hPa.Looking at the chart of the weather station found in the linked resource, we can see that theonly  day  in  the  given  range  in  december  that  matches  this  range  is  16.12.2020.   Directlink  to  the  resource\n",
    "https://www.meteoschweiz.admin.ch/home/messwerte.html?param=messwerte-luftdruck-qfe-10min&station=JUN&chart=day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.2\n",
    "Starting Location?\n",
    "=> Grindelwald\n",
    "\n",
    "# Q 2.3\n",
    "For which of the following locations is it possible and reasonable that the subject passed throughwhile the sensors were active?  (max.  3pt)Note:  A short reasoning is required for each answer, random answers will be awarded 0 points.\n",
    "* Basel (false)\n",
    "* Bern (false)\n",
    "* Grindelwald (true, starting loc)\n",
    "* Interlaken (true, on the way back home)\n",
    "* Kleine Scheidegg (46.58519, 7.96124) (false)\n",
    "* Lauterbrunnen (false)\n",
    "* Luzern (true, on the way back home)\n",
    "* Wengen (false)\n",
    "* Zurich  (true, on the way back home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0649b68a8733420a9ee114949949f9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "fig,ax=plt.subplots(nrows=2,ncols=1,figsize=(10, 6), sharex=True)\n",
    "\n",
    "for key in data:\n",
    "    ax[0].plot(data[key], label=key)\n",
    "    ax[1].plot(elevation[key], label=key)\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.1\n",
    "What is the maximum measured vertical speed of the elevator leading up to the viewing platformof sphinx observatory on Jungfraujoch?  Compute the value both for the ride up and down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max in averaged sensor traces: 6.194676648106336\n",
      "6.429508353125892\n",
      "6.33937761643642\n",
      "6.216894161446667\n",
      "6.22520567856637\n",
      "av. max across sensors: 6.302746452393837\n"
     ]
    }
   ],
   "source": [
    "s = 134100\n",
    "e = 134500\n",
    "\n",
    "time_window = 42\n",
    "summed_up = np.sum([elevation['chest'][s:e], elevation['head'][s:e], elevation['wrist'][s:e], elevation['ankle'][s:e]], axis=0)/4\n",
    "speeds = [(summed_up[i]-summed_up[i-time_window])/(time_window/13.7) for i in range(time_window, len(summed_up))] \n",
    "print(\"max in averaged sensor traces:\", max(speeds))  \n",
    "\n",
    "maxspeeds = []\n",
    "for key in data:\n",
    "    summed_up = elevation[key][s:e]\n",
    "    speeds = [(summed_up[i]-summed_up[i-time_window])/(time_window/13.7) for i in range(time_window, len(summed_up))] \n",
    "    print(max(speeds))  \n",
    "    maxspeeds.append(max(speeds))\n",
    "print(\"av. max across sensors:\",np.average(maxspeeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max in averaged sensor traces: -6.585696940616097\n",
      "-6.906558739522707\n",
      "-6.8316349207278755\n",
      "-6.395285619681355\n",
      "-6.77243257298655\n",
      "av. max across sensors: -6.726477963229621\n"
     ]
    }
   ],
   "source": [
    "s = 210200#134000 210200\n",
    "e = 210700#134500 210700\n",
    "\n",
    "time_window = 42\n",
    "summed_up = np.sum([elevation['chest'][s:e], elevation['head'][s:e], elevation['wrist'][s:e], elevation['ankle'][s:e]], axis=0)/4\n",
    "speeds = [(summed_up[i]-summed_up[i-time_window])/(time_window/13.7) for i in range(time_window, len(summed_up))] \n",
    "print(\"max in averaged sensor traces:\", min(speeds))  \n",
    "\n",
    "maxspeeds = []\n",
    "for key in data:\n",
    "    summed_up = elevation[key][s:e]\n",
    "    speeds = [(summed_up[i]-summed_up[i-time_window])/(time_window/13.7) for i in range(time_window, len(summed_up))] \n",
    "    print(min(speeds))  \n",
    "    maxspeeds.append(min(speeds))\n",
    "print(\"av. max across sensors:\",np.average(maxspeeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.2\n",
    "\n",
    "Whats the sampling rate of the accelerometer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X', 'Y', 'Z'])\n",
      "Length of trace of X-axis data: 4243321\n",
      "12387th sample of Y-axis: 113319\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "# .item() is needed as np.load() returns a structured array that needs\n",
    "# to be converted back to a dict. File should be in same location as code.\n",
    "imu_data = np.load(\"ex1_data_task3.dict.npy\", allow_pickle=True).item() \n",
    "\n",
    "print(imu_data.keys())\n",
    "print(\"Length of trace of X-axis data: {}\".format(len(imu_data[\"X\"])))\n",
    "print(\"12387th sample of Y-axis: {}\".format(imu_data[\"Y\"][12387]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.2\n",
    "\n",
    "Whats the sampling rate of the accelerometer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.03663503935792\n"
     ]
    }
   ],
   "source": [
    "print(len(imu_data[\"X\"])/len(data[\"chest\"])*13.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.3a)\n",
    "\n",
    "What percentage of the time did the subject spend walking?3You may use the length ofthe accelerometer data trace as base value for 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this task, we use the standard-deviation threshold algorithm presented in \"Walk Detection and Step Counting on Unconstrained Smartphones\", Brajdic and Harle. We calculate the total magnitude in acceleration and convert it to g. We then split it into windows of 0.8s length (or 102 samples) and compute the standard-deviation for each window. We use a slightly increased threshold compared to the paper as our IMUs are rigidly mounted and not in a smartphone. Therefore we classify each 0.8s window as walking if the std is bigger than 0.75g. This threshold adjustment from the suggested 0.6g can be done by inspecting the results for false positives and false negatives.\n",
    " After making sure, that we do not classify anything as walking while the subject sits in trains, gondolas and cars, we reach a result of 11.3%\n",
    " Tolerance for full points: +-0.5%, points awarded for tolerances of up to +-7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 128\n",
    "imu_data['imu_magnitude'] = np.sqrt(np.square(imu_data[\"X\"]/(2**18))+np.square(imu_data[\"Y\"]/(2**18))+np.square(imu_data[\"Z\"]/(2**18)))*9.81 # converted to m/s2\n",
    "# Walk Detection and Step Counting on Unconstrained Smartphones, Brajdic and Harle\n",
    "std_win = 102 # 0.8 seconds from the paper made to fit sampling rate with 102 samples\n",
    "std_x = np.array([i for i in range(0, len(imu_data['imu_magnitude'])-std_win, std_win)])\n",
    "stds = np.array([np.std(imu_data['imu_magnitude'][i:i+std_win]) for i in std_x])\n",
    "\n",
    "imu_data['walking'] = stds>0.75 # now we have walking in there\n",
    "imu_data['walking'] = imu_data['walking']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1e7d685147453f8e636074ed20842b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal\n",
    "p_resampled = scipy.signal.resample(elevation['chest'], len(imu_data['imu_magnitude']))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "fig,ax=plt.subplots(nrows=4,ncols=1,figsize=(10, 8), sharex=True)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"Elevation Profile\")\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[0].plot(p_resampled)\n",
    "\n",
    "\n",
    "ax[1].set_title(\"Walk detection\")\n",
    "ax[1].plot(std_x, stds)\n",
    "ax[1].plot(std_x,  imu_data['walking'])\n",
    "\n",
    "key = 'chest'\n",
    "\n",
    "\n",
    "ax[2].set_title(\"IMU Magnitude\")\n",
    "ax[2].plot(imu_data['imu_magnitude'])\n",
    "\n",
    "ax[3].set_title(\"IMU Data\")\n",
    "ax[3].plot(imu_data['X'])\n",
    "ax[3].plot(imu_data['Y'])\n",
    "ax[3].plot(imu_data['Z'])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually enetered activities\n",
    "sitting_intervals = []\n",
    "\n",
    "#train and gondola rides\n",
    "sitting_intervals.append([0, 335000])\n",
    "sitting_intervals.append([543000, 660000])\n",
    "sitting_intervals.append([710000, 794000])\n",
    "sitting_intervals.append([824000, 896000])\n",
    "sitting_intervals.append([2806000, 2974000])\n",
    "sitting_intervals.append([3030000, 3138000])\n",
    "sitting_intervals.append([3231000, 4243320])\n",
    "\n",
    "#Remove those periods from the walking detection\n",
    "for interval in sitting_intervals:\n",
    "    imu_data['walking'][int(interval[0]/std_win):int(interval[1]/std_win)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of walking 0.11338669743515781\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of walking\", sum(imu_data['walking'])/len(std_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.3b)\n",
    "\n",
    "How many steps did the subject take throughout the day? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again  we  take  an  algorithm  from  ”Walk  Detection  and  Step  Counting  onUnconstrained Smartphones”, Brajdic and Harle as an example:  windowed peak detection. First we smoothen the magnitude signal with a running average filter of 40 samples and then run a peak detection.  For the latter it is possible to trim the parameters to visually reduce false positives and false negatives.  Of course we only consider peaks during periods of walking.  Using a minimum prominence of 0.1g and a minimum distancebetween peaks of 0.52s, we count 5596 steps. Tolerance for full points:±400 steps, points awarded for tolerances of up to±2500 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of steps: 5596\n"
     ]
    }
   ],
   "source": [
    "imu_data['magnitude_smooth'] = scipy.ndimage.uniform_filter1d(imu_data['imu_magnitude'], 40) # .31s mov av As described in paper ”Walk Detection and Step Counting on Unconstrained Smartphones”, Brajdicand Harle\n",
    "pks,_ = scipy.signal.find_peaks(imu_data['magnitude_smooth'], prominence=0.1, distance=67) #\n",
    "\n",
    "for i, walk in enumerate(imu_data['walking']):\n",
    "    if walk == 0:\n",
    "        pks = np.delete(pks, np.logical_and(pks >= i*std_win, pks < (i+1)*std_win))\n",
    "        \n",
    "print(\"number of steps:\", len(pks))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bbac0d597a436f9f0e3d70b9ddccdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "p_resampled = scipy.signal.resample(elevation['chest'], len(imu_data['imu_magnitude']))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "fig,ax=plt.subplots(nrows=4,ncols=1,figsize=(10, 8), sharex=True)\n",
    "\n",
    "ax[0].set_title(\"Elevation Profile\")\n",
    "ax[1].set_title(\"Walk detection\")\n",
    "ax[2].set_title(\"IMU Magnitude / Step Count\")\n",
    "ax[3].set_title(\"IMU Data\")\n",
    "\n",
    "\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[0].plot(p_resampled)\n",
    "#ax[2].plot(vt.butter_bandpass_filter(height, 0.0001, 0.5, 13.7, 1))\n",
    "ax[1].plot(std_x, stds)\n",
    "ax[1].plot(std_x,  imu_data['walking'])\n",
    "\n",
    "key = 'chest'\n",
    "\n",
    "\n",
    "ax[2].plot(imu_data['imu_magnitude'], label=\"IMU magn.\")\n",
    "ax[2].plot(imu_data['magnitude_smooth'], label=\"IMU magn. averaged\")\n",
    "ax[2].plot(pks, imu_data['magnitude_smooth'][pks],  'or', label=\"Detected steps\")\n",
    "ax[2].legend(loc='lower right')\n",
    "\n",
    "ax[3].plot(imu_data['X'])\n",
    "ax[3].plot(imu_data['Y'])\n",
    "ax[3].plot(imu_data['Z'])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
